# Cursor Rules for Indexing Server

## Project Context

This is a FastAPI-based indexing server for vector embeddings and semantic search with advanced AI capabilities. The server integrates with:

- **Qdrant** as the vector database
- **Ollama** for local AI model inference (summarization, vision, and embeddings)
- **Online Models** (Gemini) via LiteLLM for cloud-based processing
- **Poetry** for dependency management
- **Specialized Vision Processing** for image content extraction

## Technology Stack

- **FastAPI**: REST API framework
- **Qdrant**: Vector database for embeddings
- **Ollama**: Local LLM for text processing and vision
- **LiteLLM**: Unified interface for local and online AI models
- **Gemini**: Online AI models for enhanced processing
- **qwen2.5-vl:7b**: Specialized vision model for image content extraction
- **Pydantic**: Data validation and settings with smart validation
- **httpx**: Async HTTP client
- **Pillow**: Image processing for vision capabilities
- **Poetry**: Python dependency management

## Code Style & Standards

- Follow PEP 8 style guidelines
- Use async/await for all I/O operations
- Use Pydantic models for request/response validation
- Include proper error handling with HTTPException
- **Fail-fast approach**: Stop processing immediately on any failure
- Add comprehensive docstrings for functions and classes
- Use type hints throughout the codebase
- Keep functions focused and single-responsibility

## Architecture Principles

- **Configuration**: All configurable values in `config.py` with smart validation
- **Error Handling**: Fail-fast approach with appropriate HTTP status codes
- **Async Operations**: All external API calls (Ollama, Qdrant, Gemini) must be async
- **Data Models**: Clear Pydantic models for all API inputs/outputs
- **Logging**: Structured logging with model selection information
- **Model Flexibility**: Support both local (Ollama) and online (Gemini) models
- **Content-Focused Processing**: Optimized for extracting searchable content

## Key Files

- `app.py`: Main FastAPI application entry point and startup configuration
- `config.py`: Pydantic settings with model selection and API key validation
- `models.py`: Pydantic data models for API requests and responses
- `database.py`: Qdrant client setup and collection management
- `services.py`: File processing, AI service functions, and model management
- `routes.py`: API route definitions and endpoint handlers
- `prompts.py`: AI prompts for summarization and specialized image analysis
- `constants.py`: File types, limits, and configuration constants
- `pyproject.toml`: Poetry dependencies and project metadata
- `.env`: Environment variables (not tracked in git)

## Architecture Organization

- **Separation of Concerns**: Each module has a specific responsibility
- **Models**: All Pydantic models centralized in `models.py`
- **Services**: External service integrations and AI processing in `services.py`
- **Database**: Qdrant operations isolated in `database.py`
- **Routes**: API endpoints organized in `routes.py`
- **Configuration**: Settings management with validation in `config.py`
- **Prompts**: Specialized AI prompts for different content types in `prompts.py`
- **Entry Point**: Clean application setup in `app.py`

## API Design

- RESTful endpoint design
- Use appropriate HTTP methods (GET, POST, PUT, DELETE)
- Include response models for documentation
- Group endpoints with tags for Swagger organization
- Return consistent error formats
- **Fail-fast processing**: Return errors immediately when processing fails

## Development Workflow

1. Use Poetry for all dependency management: `poetry add <package>`
2. Run server with: `poetry run python3 app.py`
3. Test endpoints using FastAPI's automatic docs at `/docs`
4. Create `.env` file from the comprehensive template in README
5. Ensure Qdrant and Ollama services are running (for local models)
6. Configure API keys only when using online models

## External Dependencies

### Required Services

- **Qdrant**: Must be running on configured host:port
- **Ollama** (for local models): Must have required models installed:
  - `gemma3:4b` for text summarization
  - `qwen2.5-vl:7b` for specialized vision processing
  - `nomic-embed-text` for embeddings

### Optional Services

- **Gemini API**: For online model processing (requires API key)

## Model Configuration

### Local Models (Default)

```env
USE_ONLINE_MODELS=false
OLLAMA_SUMMARY_MODEL=gemma3:4b
OLLAMA_VISION_MODEL=qwen2.5-vl:7b
OLLAMA_EMBEDDING_MODEL=nomic-embed-text
```

### Online Models (Optional)

```env
USE_ONLINE_MODELS=true
ONLINE_SUMMARY_MODEL=gemini/gemini-1.5-flash
ONLINE_VISION_MODEL=gemini/gemini-1.5-flash
GEMINI_API_KEY=your_api_key_here
```

## Common Patterns

- Always use settings from `config.py` instead of hardcoded values
- Wrap external API calls in try-catch with proper error handling
- **Fail-fast approach**: Raise HTTPException immediately on failures
- Use async context managers for HTTP clients
- Return appropriate HTTP status codes (200, 201, 400, 422, 500, 503)
- Include metadata in embedding payloads (created_at, updated_at, file_id, file_path)
- Set up environment variables for online models when needed
- Use content-focused prompts for better searchability

## Error Handling Strategy

### Fail-Fast Approach

- **Content Extraction Fails**: Stop immediately, return 422/503
- **Summarization Fails**: Stop immediately, return 503
- **Vision Processing Fails**: Stop immediately, return 422/503
- **No Partial Processing**: Only generate embeddings after successful content extraction and summarization

### HTTP Status Codes

- `200`: Success
- `201`: Created (for upsert operations)
- `400`: Bad Request (invalid input)
- `404`: Not Found (file doesn't exist)
- `413`: Payload Too Large (file size exceeded)
- `422`: Unprocessable Entity (file type issues, vision failures)
- `500`: Internal Server Error (unexpected failures)
- `503`: Service Unavailable (AI model failures)

## Testing Strategy

- Test all endpoints with various input scenarios
- Verify error handling for external service failures
- Test both local and online model configurations
- Test with invalid inputs to ensure proper validation
- Test fail-fast behavior with intentional failures
- Test vision processing with various image types
- Use the `/docs` endpoint for interactive testing during development

## Performance Considerations

- Use async operations for all I/O
- Implement proper timeout values for external API calls
- Consider chunking large text inputs for processing
- Use connection pooling for Qdrant client
- Set up API keys efficiently for online models
- Cache environment setup for performance

## Security Notes

- Input validation through Pydantic models
- Proper error handling to avoid information leakage
- **API Key Management**: Only validate API keys when online models are enabled
- Consider rate limiting for production deployments
- Use environment variables for all sensitive configuration
- Keep API keys secure and don't commit to version control

## When Adding New Features

1. Update the appropriate Pydantic models if adding new fields
2. Add proper error handling with fail-fast approach
3. Update the README documentation and .cursorrules.md
4. Add relevant configuration options to `config.py`
5. Ensure async/await patterns are maintained
6. Test with both local and online model configurations
7. Add appropriate logging with model selection information
8. Consider both local and online model scenarios

## Configuration System

- **Smart Validation**: API keys only validated when `USE_ONLINE_MODELS=true`
- **Model Flexibility**: Easy switching between local and online models
- **Environment Priority**: Environment variables → .env file → defaults
- **Fail-Safe Defaults**: Sensible defaults for all configurations
- **Comprehensive Template**: Complete .env template with all options

## API Endpoints

- `GET /` - Health check endpoint
- `POST /query` - Vector search with threshold filtering
- `POST/PUT /upsert` - Create or update file embeddings with fail-fast processing
- `DELETE /delete` - Remove file embeddings

## File Processing Strategy

### Supported File Types

- **Text Files**: Multiple encodings, graceful fallback
- **PDFs**: Page-by-page extraction with error handling
- **DOCX**: Paragraph extraction with structure preservation
- **Images**: Specialized vision processing with content-focused extraction
- **Code Files**: Multiple programming languages and config formats

### Vision Processing

- **Content-Focused**: Optimized for extracting searchable content
- **Specialized Model**: Uses qwen2.5-vl:7b or Gemini for vision
- **OCR Capability**: Extracts text from images
- **UI Element Recognition**: Identifies buttons, menus, interface components
- **Fail-Fast**: Raises errors if vision processing fails

## Logging Standards

- Use the configured logger from settings
- Include contextual information (file_id, operation type, model selection)
- Log at appropriate levels:
  - INFO: Important operations, model selection, and results
  - DEBUG: Detailed processing information and prompts
  - ERROR: Failures and exceptions with context
  - WARNING: Non-critical issues and fallbacks
- Use structured logging format with app name and timestamps
- Log model selection decisions clearly

## Modular Development Patterns

- **Adding New Models**: Update `config.py` and `services.py` setup functions
- **New Service Functions**: Add to `services.py` with proper error handling
- **Database Operations**: Add to `database.py` for Qdrant-specific operations
- **New Endpoints**: Add to `routes.py` using the APIRouter pattern
- **Configuration Changes**: Update `config.py`, README, and .cursorrules.md
- **New Prompts**: Add to `prompts.py` for specialized content types
- **Cross-Module Dependencies**: Keep imports clean and avoid circular dependencies

## File Import Guidelines

- `app.py` imports from: config, database, routes
- `routes.py` imports from: config, database, models, services
- `services.py` imports from: config, constants, prompts (with model management)
- `database.py` imports from: config (minimal dependencies)
- `models.py`: No internal imports (pure Pydantic models)
- `config.py`: No internal imports (pure configuration with validation)
- `prompts.py`: No internal imports (pure prompt templates)

## Image Processing Guidelines

### Content Extraction Focus

- **Searchability First**: Extract content that users would search for
- **Text Priority**: Capture all visible text (OCR)
- **Context Awareness**: Include relevant visual context
- **UI Elements**: Identify interactive components
- **Fail-Fast**: Don't generate embeddings for failed vision processing

### Vision Model Selection

- **Local**: qwen2.5-vl:7b via Ollama (default)
- **Online**: Gemini with vision capabilities
- **Switching**: Controlled by `USE_ONLINE_MODELS` setting

## Environment Configuration

### Required Always

```env
# Server and Database
SERVER_HOST=0.0.0.0
SERVER_PORT=5000
QDRANT_HOST=localhost
QDRANT_PORT=6333
```

### Local Models (Default)

```env
USE_ONLINE_MODELS=false
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_SUMMARY_MODEL=gemma3:4b
OLLAMA_VISION_MODEL=qwen2.5-vl:7b
OLLAMA_EMBEDDING_MODEL=nomic-embed-text
```

### Online Models (When Enabled)

```env
USE_ONLINE_MODELS=true
ONLINE_SUMMARY_MODEL=gemini/gemini-1.5-flash
ONLINE_VISION_MODEL=gemini/gemini-1.5-flash
GEMINI_API_KEY=your_actual_api_key
```

## Best Practices Summary

1. **Always fail-fast**: Stop processing immediately on any failure
2. **Model flexibility**: Support both local and online processing
3. **Smart validation**: Only validate what's needed based on configuration
4. **Content-focused**: Optimize for searchability, not just description
5. **Comprehensive logging**: Track model selection and processing decisions
6. **Error clarity**: Provide clear, actionable error messages
7. **Configuration completeness**: Provide comprehensive .env templates
8. **Security awareness**: Manage API keys properly and securely
